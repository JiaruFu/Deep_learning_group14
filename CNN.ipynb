{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import re \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# Need to load the large model to get the vectors\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# read the text file and add the column names\n",
    "read_file = pd.read_csv(r\"booksummaries.txt\", sep='\t', header=None)\n",
    "read_file.columns = ['ID', 'm number', 'book name', 'author name', 'date', 'label', 'summary']\n",
    "\n",
    "# clean data\n",
    "read_file['label'] = read_file['label'].str.replace(r'/m/\\S*\\s', '')\n",
    "read_file['label'] = read_file['label'].str.replace(r'{', '')\n",
    "read_file['label'] = read_file['label'].str.replace(r'}', '')\n",
    "read_file['label'] = read_file['label'].str.replace(r'}', '')\n",
    "read_file['label'] = read_file['label'].str.replace(r'\\\\u00e0\\s+clef', '')\n",
    "\n",
    "# select columns\n",
    "new_file = read_file.loc[:, ['book name', 'label', 'summary']]\n",
    "\n",
    "#delete the columns with no labels\n",
    "new_file.dropna(axis = 0, how = 'any', inplace = True)\n",
    "new_file = new_file.iloc[:, [0, 2, 1]]\n",
    "\n",
    "new_file = new_file.reset_index(drop=True)\n",
    "\n",
    "#output data as csv\n",
    "new_file.to_csv(r'./booksummries.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book name</th>\n",
       "      <th>summary</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>Old Major, the old boar on the Manor Farm, ca...</td>\n",
       "      <td>\"\"Roman \", \"\"Satire\", \"\"Children's literature\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>Alex, a teenager living in near-future Englan...</td>\n",
       "      <td>\"\"Science Fiction\", \"\"Novella\", \"\"Speculative ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Plague</td>\n",
       "      <td>The text of The Plague is divided into five p...</td>\n",
       "      <td>\"\"Existentialism\", \"\"Fiction\", \"\"Absurdist fic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Fire Upon the Deep</td>\n",
       "      <td>The novel posits that space around the Milky ...</td>\n",
       "      <td>\"\"Hard science fiction\", \"\"Science Fiction\", \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All Quiet on the Western Front</td>\n",
       "      <td>The book tells the story of Paul Bäumer, a Ge...</td>\n",
       "      <td>\"\"War novel\", \"\"Roman \"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        book name  \\\n",
       "0                     Animal Farm   \n",
       "1              A Clockwork Orange   \n",
       "2                      The Plague   \n",
       "3            A Fire Upon the Deep   \n",
       "4  All Quiet on the Western Front   \n",
       "\n",
       "                                             summary  \\\n",
       "0   Old Major, the old boar on the Manor Farm, ca...   \n",
       "1   Alex, a teenager living in near-future Englan...   \n",
       "2   The text of The Plague is divided into five p...   \n",
       "3   The novel posits that space around the Milky ...   \n",
       "4   The book tells the story of Paul Bäumer, a Ge...   \n",
       "\n",
       "                                               label  \n",
       "0  \"\"Roman \", \"\"Satire\", \"\"Children's literature\"...  \n",
       "1  \"\"Science Fiction\", \"\"Novella\", \"\"Speculative ...  \n",
       "2  \"\"Existentialism\", \"\"Fiction\", \"\"Absurdist fic...  \n",
       "3  \"\"Hard science fiction\", \"\"Science Fiction\", \"...  \n",
       "4                            \"\"War novel\", \"\"Roman \"  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(label_list):\n",
    "    has_fiction = False\n",
    "    has_spec_fiction = False\n",
    "    has_novel = False\n",
    "    has_spec_novel = False\n",
    "    for i in range(len(label_list)):\n",
    "        if 'novel' in label_list[i].lower():\n",
    "            if 'novel' == label_list[i].lower():\n",
    "                has_novel = True\n",
    "            else:\n",
    "                has_spec_novel = True\n",
    "        if 'fiction' in label_list[i].lower():\n",
    "            if 'fiction' == label_list[i].lower():\n",
    "                has_fiction = True\n",
    "            else:\n",
    "                has_spec_fiction = True\n",
    "        \n",
    "    if has_spec_fiction and has_spec_novel:\n",
    "        if has_fiction:\n",
    "            label_list.remove('fiction')\n",
    "        if has_novel:\n",
    "            label_list.remove('novel')\n",
    "    elif has_spec_fiction:\n",
    "        if has_fiction:\n",
    "            label_list.remove('fiction')\n",
    "        if has_novel:\n",
    "            label_list.remove('novel')\n",
    "    elif has_spec_novel:\n",
    "        if has_fiction:\n",
    "            label_list.remove('fiction')\n",
    "        if has_novel:\n",
    "            label_list.remove('novel')\n",
    "    elif has_fiction and has_novel:\n",
    "        label_list.remove('fiction')\n",
    "    return label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(new_file['label'])):\n",
    "    label = new_file['label'][index].replace('\"', ''). lower()\n",
    "    label_list = re.split(', ', label)  \n",
    "    label_list = text_process(label_list)\n",
    "    new_file.xs(index)['label']= label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output data as csv\n",
    "new_file.to_csv(r'./booksummries.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book name</th>\n",
       "      <th>summary</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12836</th>\n",
       "      <td>The Third Lynx</td>\n",
       "      <td>The story starts with former government agent...</td>\n",
       "      <td>[science fiction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12837</th>\n",
       "      <td>Remote Control</td>\n",
       "      <td>The series follows the character of Nick Ston...</td>\n",
       "      <td>[thriller, fiction, suspense]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12838</th>\n",
       "      <td>Transfer of Power</td>\n",
       "      <td>The reader first meets Rapp while he is doing...</td>\n",
       "      <td>[thriller, fiction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12839</th>\n",
       "      <td>Decoded</td>\n",
       "      <td>The book follows very rough chronological ord...</td>\n",
       "      <td>[autobiography]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12840</th>\n",
       "      <td>Poor Folk</td>\n",
       "      <td>Makar Devushkin and Varvara Dobroselova are s...</td>\n",
       "      <td>[epistolary novel, speculative fiction]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               book name                                            summary  \\\n",
       "12836     The Third Lynx   The story starts with former government agent...   \n",
       "12837     Remote Control   The series follows the character of Nick Ston...   \n",
       "12838  Transfer of Power   The reader first meets Rapp while he is doing...   \n",
       "12839            Decoded   The book follows very rough chronological ord...   \n",
       "12840          Poor Folk   Makar Devushkin and Varvara Dobroselova are s...   \n",
       "\n",
       "                                         label  \n",
       "12836                        [science fiction]  \n",
       "12837            [thriller, fiction, suspense]  \n",
       "12838                      [thriller, fiction]  \n",
       "12839                          [autobiography]  \n",
       "12840  [epistolary novel, speculative fiction]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_file.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Encoding the Labels##\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = []\n",
    "for index in range(len(new_file['label'])):\n",
    "    object_label = new_file['label'][index]\n",
    "    for l in object_label:\n",
    "        if l not in label_list:\n",
    "            label_list.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.DataFrame(np.zeros((12841, 227)), columns=label_list).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(new_file['label'])):\n",
    "    object_label = new_file['label'][index]\n",
    "    for l in object_label:\n",
    "        one_hot[l][index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roman</th>\n",
       "      <th>satire</th>\n",
       "      <th>children's literature</th>\n",
       "      <th>speculative fiction</th>\n",
       "      <th>science fiction</th>\n",
       "      <th>novella</th>\n",
       "      <th>utopian and dystopian fiction</th>\n",
       "      <th>existentialism</th>\n",
       "      <th>absurdist fiction</th>\n",
       "      <th>hard science fiction</th>\n",
       "      <th>...</th>\n",
       "      <th>encyclopedia</th>\n",
       "      <th>mashup</th>\n",
       "      <th>biopunk</th>\n",
       "      <th>popular culture</th>\n",
       "      <th>neuroscience</th>\n",
       "      <th>new york times best seller list</th>\n",
       "      <th>epic science fiction and fantasy</th>\n",
       "      <th>alien invasion</th>\n",
       "      <th>prose</th>\n",
       "      <th>pastiche</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12836</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12837</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12838</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12839</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12840</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12841 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       roman   satire  children's literature  speculative fiction  \\\n",
       "0           1       1                      1                    1   \n",
       "1           0       1                      0                    1   \n",
       "2           0       0                      0                    0   \n",
       "3           0       0                      0                    1   \n",
       "4           1       0                      0                    0   \n",
       "...       ...     ...                    ...                  ...   \n",
       "12836       0       0                      0                    0   \n",
       "12837       0       0                      0                    0   \n",
       "12838       0       0                      0                    0   \n",
       "12839       0       0                      0                    0   \n",
       "12840       0       0                      0                    1   \n",
       "\n",
       "       science fiction  novella  utopian and dystopian fiction  \\\n",
       "0                    0        0                              0   \n",
       "1                    1        1                              1   \n",
       "2                    0        0                              0   \n",
       "3                    1        0                              0   \n",
       "4                    0        0                              0   \n",
       "...                ...      ...                            ...   \n",
       "12836                1        0                              0   \n",
       "12837                0        0                              0   \n",
       "12838                0        0                              0   \n",
       "12839                0        0                              0   \n",
       "12840                0        0                              0   \n",
       "\n",
       "       existentialism  absurdist fiction  hard science fiction  ...  \\\n",
       "0                   0                  0                     0  ...   \n",
       "1                   0                  0                     0  ...   \n",
       "2                   1                  1                     0  ...   \n",
       "3                   0                  0                     1  ...   \n",
       "4                   0                  0                     0  ...   \n",
       "...               ...                ...                   ...  ...   \n",
       "12836               0                  0                     0  ...   \n",
       "12837               0                  0                     0  ...   \n",
       "12838               0                  0                     0  ...   \n",
       "12839               0                  0                     0  ...   \n",
       "12840               0                  0                     0  ...   \n",
       "\n",
       "       encyclopedia  mashup  biopunk  popular culture  neuroscience  \\\n",
       "0                 0       0        0                0             0   \n",
       "1                 0       0        0                0             0   \n",
       "2                 0       0        0                0             0   \n",
       "3                 0       0        0                0             0   \n",
       "4                 0       0        0                0             0   \n",
       "...             ...     ...      ...              ...           ...   \n",
       "12836             0       0        0                0             0   \n",
       "12837             0       0        0                0             0   \n",
       "12838             0       0        0                0             0   \n",
       "12839             0       0        0                0             0   \n",
       "12840             0       0        0                0             0   \n",
       "\n",
       "       new york times best seller list  epic science fiction and fantasy  \\\n",
       "0                                    0                                 0   \n",
       "1                                    0                                 0   \n",
       "2                                    0                                 0   \n",
       "3                                    0                                 0   \n",
       "4                                    0                                 0   \n",
       "...                                ...                               ...   \n",
       "12836                                0                                 0   \n",
       "12837                                0                                 0   \n",
       "12838                                0                                 0   \n",
       "12839                                0                                 0   \n",
       "12840                                0                                 0   \n",
       "\n",
       "       alien invasion  prose  pastiche  \n",
       "0                   0      0         0  \n",
       "1                   0      0         0  \n",
       "2                   0      0         0  \n",
       "3                   0      0         0  \n",
       "4                   0      0         0  \n",
       "...               ...    ...       ...  \n",
       "12836               0      0         0  \n",
       "12837               0      0         0  \n",
       "12838               0      0         0  \n",
       "12839               0      0         0  \n",
       "12840               0      0         0  \n",
       "\n",
       "[12841 rows x 227 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the words##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "def words_process(new_file):\n",
    "    book_summaries = new_file['summary']\n",
    "    summary_list = [summary for summary in book_summaries]\n",
    "    summary_num = len(summary_list)\n",
    "    #summaries = ''.join(summary_list)\n",
    "    print(\"the total number of books: {}\\n\".format(summary_num))\n",
    "    \n",
    "    all_docs = []\n",
    "\n",
    "    for doc in summary_list:\n",
    "        # Tokenize the string into words\n",
    "        tokens = word_tokenize(doc)\n",
    "        # Remove non-alphabetic tokens, such as punctuation\n",
    "        words = [word.lower() for word in tokens if word.isalpha()]\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        words = [word for word in words if not word in stop_words]\n",
    "        all_docs.append(words)\n",
    "        \n",
    "    return all_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total number of books: 3\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['old',\n",
       "  'major',\n",
       "  'old',\n",
       "  'boar',\n",
       "  'manor',\n",
       "  'farm',\n",
       "  'calls',\n",
       "  'animals',\n",
       "  'farm',\n",
       "  'meeting',\n",
       "  'compares',\n",
       "  'humans',\n",
       "  'parasites',\n",
       "  'teaches',\n",
       "  'animals',\n",
       "  'revolutionary',\n",
       "  'song',\n",
       "  'england',\n",
       "  'major',\n",
       "  'dies',\n",
       "  'two',\n",
       "  'young',\n",
       "  'pigs',\n",
       "  'snowball',\n",
       "  'napoleon',\n",
       "  'assume',\n",
       "  'command',\n",
       "  'turn',\n",
       "  'dream',\n",
       "  'philosophy',\n",
       "  'animals',\n",
       "  'revolt',\n",
       "  'drive',\n",
       "  'drunken',\n",
       "  'irresponsible',\n",
       "  'mr',\n",
       "  'jones',\n",
       "  'farm',\n",
       "  'renaming',\n",
       "  'animal',\n",
       "  'farm',\n",
       "  'adopt',\n",
       "  'seven',\n",
       "  'commandments',\n",
       "  'important',\n",
       "  'animals',\n",
       "  'equal',\n",
       "  'snowball',\n",
       "  'attempts',\n",
       "  'teach',\n",
       "  'animals',\n",
       "  'reading',\n",
       "  'writing',\n",
       "  'food',\n",
       "  'plentiful',\n",
       "  'farm',\n",
       "  'runs',\n",
       "  'smoothly',\n",
       "  'pigs',\n",
       "  'elevate',\n",
       "  'positions',\n",
       "  'leadership',\n",
       "  'set',\n",
       "  'aside',\n",
       "  'special',\n",
       "  'food',\n",
       "  'items',\n",
       "  'ostensibly',\n",
       "  'personal',\n",
       "  'health',\n",
       "  'napoleon',\n",
       "  'takes',\n",
       "  'pups',\n",
       "  'farm',\n",
       "  'dogs',\n",
       "  'trains',\n",
       "  'privately',\n",
       "  'napoleon',\n",
       "  'snowball',\n",
       "  'struggle',\n",
       "  'leadership',\n",
       "  'snowball',\n",
       "  'announces',\n",
       "  'plans',\n",
       "  'build',\n",
       "  'windmill',\n",
       "  'napoleon',\n",
       "  'dogs',\n",
       "  'chase',\n",
       "  'snowball',\n",
       "  'away',\n",
       "  'declares',\n",
       "  'leader',\n",
       "  'napoleon',\n",
       "  'enacts',\n",
       "  'changes',\n",
       "  'governance',\n",
       "  'structure',\n",
       "  'farm',\n",
       "  'replacing',\n",
       "  'meetings',\n",
       "  'committee',\n",
       "  'pigs',\n",
       "  'run',\n",
       "  'farm',\n",
       "  'using',\n",
       "  'young',\n",
       "  'pig',\n",
       "  'named',\n",
       "  'squealer',\n",
       "  'mouthpiece',\n",
       "  'napoleon',\n",
       "  'claims',\n",
       "  'credit',\n",
       "  'windmill',\n",
       "  'idea',\n",
       "  'animals',\n",
       "  'work',\n",
       "  'harder',\n",
       "  'promise',\n",
       "  'easier',\n",
       "  'lives',\n",
       "  'windmill',\n",
       "  'violent',\n",
       "  'storm',\n",
       "  'animals',\n",
       "  'find',\n",
       "  'windmill',\n",
       "  'annihilated',\n",
       "  'napoleon',\n",
       "  'squealer',\n",
       "  'convince',\n",
       "  'animals',\n",
       "  'snowball',\n",
       "  'destroyed',\n",
       "  'although',\n",
       "  'scorn',\n",
       "  'neighbouring',\n",
       "  'farmers',\n",
       "  'suggests',\n",
       "  'walls',\n",
       "  'thin',\n",
       "  'snowball',\n",
       "  'becomes',\n",
       "  'scapegoat',\n",
       "  'napoleon',\n",
       "  'begins',\n",
       "  'purging',\n",
       "  'farm',\n",
       "  'dogs',\n",
       "  'killing',\n",
       "  'animals',\n",
       "  'accuses',\n",
       "  'consorting',\n",
       "  'old',\n",
       "  'rival',\n",
       "  'pigs',\n",
       "  'abuse',\n",
       "  'power',\n",
       "  'imposing',\n",
       "  'control',\n",
       "  'reserving',\n",
       "  'privileges',\n",
       "  'rewriting',\n",
       "  'history',\n",
       "  'villainising',\n",
       "  'snowball',\n",
       "  'glorifying',\n",
       "  'napoleon',\n",
       "  'squealer',\n",
       "  'justifies',\n",
       "  'every',\n",
       "  'statement',\n",
       "  'napoleon',\n",
       "  'makes',\n",
       "  'even',\n",
       "  'pigs',\n",
       "  'alteration',\n",
       "  'seven',\n",
       "  'commandments',\n",
       "  'animalism',\n",
       "  'benefit',\n",
       "  'england',\n",
       "  'replaced',\n",
       "  'anthem',\n",
       "  'glorifying',\n",
       "  'napoleon',\n",
       "  'appears',\n",
       "  'adopting',\n",
       "  'lifestyle',\n",
       "  'man',\n",
       "  'animals',\n",
       "  'remain',\n",
       "  'convinced',\n",
       "  'better',\n",
       "  'mr',\n",
       "  'jones',\n",
       "  'squealer',\n",
       "  'abuses',\n",
       "  'animals',\n",
       "  'poor',\n",
       "  'memories',\n",
       "  'invents',\n",
       "  'numbers',\n",
       "  'show',\n",
       "  'improvement',\n",
       "  'mr',\n",
       "  'frederick',\n",
       "  'one',\n",
       "  'neighbouring',\n",
       "  'farmers',\n",
       "  'attacks',\n",
       "  'farm',\n",
       "  'using',\n",
       "  'blasting',\n",
       "  'powder',\n",
       "  'blow',\n",
       "  'restored',\n",
       "  'windmill',\n",
       "  'though',\n",
       "  'animals',\n",
       "  'win',\n",
       "  'battle',\n",
       "  'great',\n",
       "  'cost',\n",
       "  'many',\n",
       "  'including',\n",
       "  'boxer',\n",
       "  'workhorse',\n",
       "  'wounded',\n",
       "  'despite',\n",
       "  'injuries',\n",
       "  'boxer',\n",
       "  'continues',\n",
       "  'working',\n",
       "  'harder',\n",
       "  'harder',\n",
       "  'collapses',\n",
       "  'working',\n",
       "  'windmill',\n",
       "  'napoleon',\n",
       "  'sends',\n",
       "  'van',\n",
       "  'take',\n",
       "  'boxer',\n",
       "  'veterinary',\n",
       "  'surgeon',\n",
       "  'explaining',\n",
       "  'better',\n",
       "  'care',\n",
       "  'given',\n",
       "  'benjamin',\n",
       "  'cynical',\n",
       "  'donkey',\n",
       "  'could',\n",
       "  'read',\n",
       "  'well',\n",
       "  'pig',\n",
       "  'notices',\n",
       "  'van',\n",
       "  'belongs',\n",
       "  'knacker',\n",
       "  'attempts',\n",
       "  'mount',\n",
       "  'rescue',\n",
       "  'animals',\n",
       "  'attempts',\n",
       "  'futile',\n",
       "  'squealer',\n",
       "  'reports',\n",
       "  'van',\n",
       "  'purchased',\n",
       "  'hospital',\n",
       "  'writing',\n",
       "  'previous',\n",
       "  'owner',\n",
       "  'repainted',\n",
       "  'recounts',\n",
       "  'tale',\n",
       "  'boxer',\n",
       "  'death',\n",
       "  'hands',\n",
       "  'best',\n",
       "  'medical',\n",
       "  'care',\n",
       "  'years',\n",
       "  'pass',\n",
       "  'pigs',\n",
       "  'learn',\n",
       "  'walk',\n",
       "  'upright',\n",
       "  'carry',\n",
       "  'whips',\n",
       "  'wear',\n",
       "  'clothes',\n",
       "  'seven',\n",
       "  'commandments',\n",
       "  'reduced',\n",
       "  'single',\n",
       "  'phrase',\n",
       "  'animals',\n",
       "  'equal',\n",
       "  'animals',\n",
       "  'equal',\n",
       "  'others',\n",
       "  'napoleon',\n",
       "  'holds',\n",
       "  'dinner',\n",
       "  'party',\n",
       "  'pigs',\n",
       "  'humans',\n",
       "  'area',\n",
       "  'congratulate',\n",
       "  'napoleon',\n",
       "  'least',\n",
       "  'fed',\n",
       "  'animals',\n",
       "  'country',\n",
       "  'napoleon',\n",
       "  'announces',\n",
       "  'alliance',\n",
       "  'humans',\n",
       "  'labouring',\n",
       "  'classes',\n",
       "  'worlds',\n",
       "  'abolishes',\n",
       "  'practices',\n",
       "  'traditions',\n",
       "  'related',\n",
       "  'revolution',\n",
       "  'changes',\n",
       "  'name',\n",
       "  'farm',\n",
       "  'manor',\n",
       "  'farm',\n",
       "  'animals',\n",
       "  'overhearing',\n",
       "  'conversation',\n",
       "  'notice',\n",
       "  'faces',\n",
       "  'pigs',\n",
       "  'begun',\n",
       "  'changing',\n",
       "  'poker',\n",
       "  'match',\n",
       "  'argument',\n",
       "  'breaks',\n",
       "  'napoleon',\n",
       "  'mr',\n",
       "  'pilkington',\n",
       "  'animals',\n",
       "  'realise',\n",
       "  'faces',\n",
       "  'pigs',\n",
       "  'look',\n",
       "  'like',\n",
       "  'faces',\n",
       "  'humans',\n",
       "  'one',\n",
       "  'tell',\n",
       "  'difference',\n",
       "  'pigs',\n",
       "  'snowball',\n",
       "  'napoleon',\n",
       "  'squealer',\n",
       "  'adapt',\n",
       "  'old',\n",
       "  'major',\n",
       "  'ideas',\n",
       "  'actual',\n",
       "  'philosophy',\n",
       "  'formally',\n",
       "  'name',\n",
       "  'animalism',\n",
       "  'soon',\n",
       "  'napoleon',\n",
       "  'squealer',\n",
       "  'indulge',\n",
       "  'vices',\n",
       "  'humans',\n",
       "  'drinking',\n",
       "  'alcohol',\n",
       "  'sleeping',\n",
       "  'beds',\n",
       "  'trading',\n",
       "  'squealer',\n",
       "  'employed',\n",
       "  'alter',\n",
       "  'seven',\n",
       "  'commandments',\n",
       "  'account',\n",
       "  'humanisation',\n",
       "  'allusion',\n",
       "  'soviet',\n",
       "  'government',\n",
       "  'revising',\n",
       "  'history',\n",
       "  'order',\n",
       "  'exercise',\n",
       "  'control',\n",
       "  'people',\n",
       "  'beliefs',\n",
       "  'society',\n",
       "  'original',\n",
       "  'commandments',\n",
       "  'whatever',\n",
       "  'goes',\n",
       "  'upon',\n",
       "  'two',\n",
       "  'legs',\n",
       "  'enemy',\n",
       "  'whatever',\n",
       "  'goes',\n",
       "  'upon',\n",
       "  'four',\n",
       "  'legs',\n",
       "  'wings',\n",
       "  'friend',\n",
       "  'animal',\n",
       "  'shall',\n",
       "  'wear',\n",
       "  'clothes',\n",
       "  'animal',\n",
       "  'shall',\n",
       "  'sleep',\n",
       "  'bed',\n",
       "  'animal',\n",
       "  'shall',\n",
       "  'drink',\n",
       "  'alcohol',\n",
       "  'animal',\n",
       "  'shall',\n",
       "  'kill',\n",
       "  'animal',\n",
       "  'animals',\n",
       "  'equal',\n",
       "  'later',\n",
       "  'napoleon',\n",
       "  'pigs',\n",
       "  'secretly',\n",
       "  'revise',\n",
       "  'commandments',\n",
       "  'clear',\n",
       "  'accusations',\n",
       "  'animal',\n",
       "  'shall',\n",
       "  'drink',\n",
       "  'alcohol',\n",
       "  'excess',\n",
       "  'appended',\n",
       "  'animal',\n",
       "  'shall',\n",
       "  'sleep',\n",
       "  'bed',\n",
       "  'sheets',\n",
       "  'added',\n",
       "  'changed',\n",
       "  'commandments',\n",
       "  'follows',\n",
       "  'changes',\n",
       "  'bolded',\n",
       "  'animal',\n",
       "  'shall',\n",
       "  'sleep',\n",
       "  'bed',\n",
       "  'sheets',\n",
       "  'animal',\n",
       "  'shall',\n",
       "  'drink',\n",
       "  'alcohol',\n",
       "  'excess',\n",
       "  'animal',\n",
       "  'shall',\n",
       "  'kill',\n",
       "  'animal',\n",
       "  'without',\n",
       "  'cause',\n",
       "  'eventually',\n",
       "  'replaced',\n",
       "  'maxims',\n",
       "  'animals',\n",
       "  'equal',\n",
       "  'animals',\n",
       "  'equal',\n",
       "  'others',\n",
       "  'four',\n",
       "  'legs',\n",
       "  'good',\n",
       "  'two',\n",
       "  'legs',\n",
       "  'better',\n",
       "  'pigs',\n",
       "  'become',\n",
       "  'human',\n",
       "  'ironic',\n",
       "  'twist',\n",
       "  'original',\n",
       "  'purpose',\n",
       "  'seven',\n",
       "  'commandments',\n",
       "  'supposed',\n",
       "  'keep',\n",
       "  'order',\n",
       "  'within',\n",
       "  'animal',\n",
       "  'farm',\n",
       "  'uniting',\n",
       "  'animals',\n",
       "  'together',\n",
       "  'humans',\n",
       "  'prevent',\n",
       "  'animals',\n",
       "  'following',\n",
       "  'humans',\n",
       "  'evil',\n",
       "  'habits',\n",
       "  'revision',\n",
       "  'commandments',\n",
       "  'orwell',\n",
       "  'demonstrates',\n",
       "  'simply',\n",
       "  'political',\n",
       "  'dogma',\n",
       "  'turned',\n",
       "  'malleable',\n",
       "  'propaganda'],\n",
       " ['alex',\n",
       "  'teenager',\n",
       "  'living',\n",
       "  'england',\n",
       "  'leads',\n",
       "  'gang',\n",
       "  'nightly',\n",
       "  'orgies',\n",
       "  'opportunistic',\n",
       "  'random',\n",
       "  'alex',\n",
       "  'friends',\n",
       "  'droogs',\n",
       "  'novel',\n",
       "  'slang',\n",
       "  'nadsat',\n",
       "  'dim',\n",
       "  'bruiser',\n",
       "  'gang',\n",
       "  'muscle',\n",
       "  'georgie',\n",
       "  'ambitious',\n",
       "  'pete',\n",
       "  'mostly',\n",
       "  'plays',\n",
       "  'along',\n",
       "  'droogs',\n",
       "  'indulge',\n",
       "  'taste',\n",
       "  'characterized',\n",
       "  'sociopath',\n",
       "  'hardened',\n",
       "  'juvenile',\n",
       "  'delinquent',\n",
       "  'alex',\n",
       "  'also',\n",
       "  'intelligent',\n",
       "  'sophisticated',\n",
       "  'taste',\n",
       "  'music',\n",
       "  'particularly',\n",
       "  'fond',\n",
       "  'beethoven',\n",
       "  'lovely',\n",
       "  'ludwig',\n",
       "  'van',\n",
       "  'novel',\n",
       "  'begins',\n",
       "  'droogs',\n",
       "  'sitting',\n",
       "  'favorite',\n",
       "  'hangout',\n",
       "  'korova',\n",
       "  'milkbar',\n",
       "  'drinking',\n",
       "  'cocktails',\n",
       "  'called',\n",
       "  'hype',\n",
       "  'night',\n",
       "  'mayhem',\n",
       "  'assault',\n",
       "  'scholar',\n",
       "  'walking',\n",
       "  'home',\n",
       "  'public',\n",
       "  'library',\n",
       "  'rob',\n",
       "  'store',\n",
       "  'leaving',\n",
       "  'owner',\n",
       "  'wife',\n",
       "  'bloodied',\n",
       "  'unconscious',\n",
       "  'stomp',\n",
       "  'panhandling',\n",
       "  'derelict',\n",
       "  'scuffle',\n",
       "  'rival',\n",
       "  'gang',\n",
       "  'joyriding',\n",
       "  'countryside',\n",
       "  'stolen',\n",
       "  'car',\n",
       "  'break',\n",
       "  'isolated',\n",
       "  'cottage',\n",
       "  'maul',\n",
       "  'young',\n",
       "  'couple',\n",
       "  'living',\n",
       "  'beating',\n",
       "  'husband',\n",
       "  'raping',\n",
       "  'wife',\n",
       "  'metafictional',\n",
       "  'touch',\n",
       "  'husband',\n",
       "  'writer',\n",
       "  'working',\n",
       "  'manuscript',\n",
       "  'called',\n",
       "  'clockwork',\n",
       "  'orange',\n",
       "  'alex',\n",
       "  'contemptuously',\n",
       "  'reads',\n",
       "  'paragraph',\n",
       "  'states',\n",
       "  'novel',\n",
       "  'main',\n",
       "  'theme',\n",
       "  'shredding',\n",
       "  'manuscript',\n",
       "  'back',\n",
       "  'milk',\n",
       "  'bar',\n",
       "  'alex',\n",
       "  'punishes',\n",
       "  'dim',\n",
       "  'crude',\n",
       "  'behaviour',\n",
       "  'strains',\n",
       "  'within',\n",
       "  'gang',\n",
       "  'become',\n",
       "  'apparent',\n",
       "  'home',\n",
       "  'dreary',\n",
       "  'flat',\n",
       "  'alex',\n",
       "  'plays',\n",
       "  'classical',\n",
       "  'music',\n",
       "  'top',\n",
       "  'volume',\n",
       "  'fantasizing',\n",
       "  'even',\n",
       "  'orgiastic',\n",
       "  'violence',\n",
       "  'alex',\n",
       "  'skips',\n",
       "  'school',\n",
       "  'next',\n",
       "  'day',\n",
       "  'following',\n",
       "  'unexpected',\n",
       "  'visit',\n",
       "  'deltoid',\n",
       "  'advisor',\n",
       "  'alex',\n",
       "  'meets',\n",
       "  'pair',\n",
       "  'girls',\n",
       "  'takes',\n",
       "  'back',\n",
       "  'parents',\n",
       "  'flat',\n",
       "  'administers',\n",
       "  'hard',\n",
       "  'drugs',\n",
       "  'rapes',\n",
       "  'evening',\n",
       "  'alex',\n",
       "  'finds',\n",
       "  'droogs',\n",
       "  'mutinous',\n",
       "  'mood',\n",
       "  'georgie',\n",
       "  'challenges',\n",
       "  'alex',\n",
       "  'leadership',\n",
       "  'gang',\n",
       "  'demanding',\n",
       "  'pull',\n",
       "  'job',\n",
       "  'alex',\n",
       "  'quells',\n",
       "  'rebellion',\n",
       "  'slashing',\n",
       "  'dim',\n",
       "  'hand',\n",
       "  'fighting',\n",
       "  'georgie',\n",
       "  'show',\n",
       "  'generosity',\n",
       "  'takes',\n",
       "  'bar',\n",
       "  'alex',\n",
       "  'insists',\n",
       "  'following',\n",
       "  'georgie',\n",
       "  'idea',\n",
       "  'burgle',\n",
       "  'home',\n",
       "  'wealthy',\n",
       "  'old',\n",
       "  'woman',\n",
       "  'starts',\n",
       "  'farce',\n",
       "  'ends',\n",
       "  'tragic',\n",
       "  'pathos',\n",
       "  'alex',\n",
       "  'attack',\n",
       "  'kills',\n",
       "  'elderly',\n",
       "  'woman',\n",
       "  'escape',\n",
       "  'blocked',\n",
       "  'dim',\n",
       "  'attacks',\n",
       "  'alex',\n",
       "  'leaving',\n",
       "  'incapacitated',\n",
       "  'front',\n",
       "  'step',\n",
       "  'police',\n",
       "  'arrive',\n",
       "  'sentenced',\n",
       "  'prison',\n",
       "  'murder',\n",
       "  'alex',\n",
       "  'gets',\n",
       "  'job',\n",
       "  'wing',\n",
       "  'chapel',\n",
       "  'playing',\n",
       "  'religious',\n",
       "  'music',\n",
       "  'stereo',\n",
       "  'services',\n",
       "  'well',\n",
       "  'singing',\n",
       "  'hymns',\n",
       "  'prison',\n",
       "  'chaplain',\n",
       "  'mistakes',\n",
       "  'alex',\n",
       "  'bible',\n",
       "  'studies',\n",
       "  'stirrings',\n",
       "  'faith',\n",
       "  'alex',\n",
       "  'actually',\n",
       "  'reading',\n",
       "  'scripture',\n",
       "  'violent',\n",
       "  'passages',\n",
       "  'alex',\n",
       "  'fellow',\n",
       "  'cellmates',\n",
       "  'blame',\n",
       "  'beating',\n",
       "  'troublesome',\n",
       "  'cellmate',\n",
       "  'death',\n",
       "  'agrees',\n",
       "  'undergo',\n",
       "  'experimental',\n",
       "  'treatment',\n",
       "  'called',\n",
       "  'ludovico',\n",
       "  'technique',\n",
       "  'technique',\n",
       "  'form',\n",
       "  'aversion',\n",
       "  'therapy',\n",
       "  'alex',\n",
       "  'receives',\n",
       "  'injection',\n",
       "  'makes',\n",
       "  'feel',\n",
       "  'sick',\n",
       "  'watching',\n",
       "  'graphically',\n",
       "  'violent',\n",
       "  'films',\n",
       "  'eventually',\n",
       "  'conditioning',\n",
       "  'suffer',\n",
       "  'crippling',\n",
       "  'bouts',\n",
       "  'nausea',\n",
       "  'mere',\n",
       "  'thought',\n",
       "  'violence',\n",
       "  'unintended',\n",
       "  'consequence',\n",
       "  'soundtrack',\n",
       "  'one',\n",
       "  'fifth',\n",
       "  'alex',\n",
       "  'unable',\n",
       "  'listen',\n",
       "  'beloved',\n",
       "  'classical',\n",
       "  'music',\n",
       "  'effectiveness',\n",
       "  'technique',\n",
       "  'demonstrated',\n",
       "  'group',\n",
       "  'vips',\n",
       "  'watch',\n",
       "  'alex',\n",
       "  'collapses',\n",
       "  'walloping',\n",
       "  'bully',\n",
       "  'abases',\n",
       "  'young',\n",
       "  'woman',\n",
       "  'whose',\n",
       "  'presence',\n",
       "  'aroused',\n",
       "  'predatory',\n",
       "  'sexual',\n",
       "  'inclinations',\n",
       "  'though',\n",
       "  'prison',\n",
       "  'chaplain',\n",
       "  'accuses',\n",
       "  'state',\n",
       "  'stripping',\n",
       "  'alex',\n",
       "  'free',\n",
       "  'government',\n",
       "  'officials',\n",
       "  'scene',\n",
       "  'pleased',\n",
       "  'results',\n",
       "  'alex',\n",
       "  'released',\n",
       "  'society',\n",
       "  'since',\n",
       "  'parents',\n",
       "  'renting',\n",
       "  'room',\n",
       "  'lodger',\n",
       "  'alex',\n",
       "  'wanders',\n",
       "  'streets',\n",
       "  'enters',\n",
       "  'public',\n",
       "  'library',\n",
       "  'hopes',\n",
       "  'learn',\n",
       "  'painless',\n",
       "  'way',\n",
       "  'commit',\n",
       "  'suicide',\n",
       "  'accidentally',\n",
       "  'encounters',\n",
       "  'old',\n",
       "  'scholar',\n",
       "  'assaulted',\n",
       "  'earlier',\n",
       "  'book',\n",
       "  'keen',\n",
       "  'revenge',\n",
       "  'beats',\n",
       "  'alex',\n",
       "  'help',\n",
       "  'friends',\n",
       "  'policemen',\n",
       "  'come',\n",
       "  'alex',\n",
       "  'rescue',\n",
       "  'turn',\n",
       "  'none',\n",
       "  'dim',\n",
       "  'former',\n",
       "  'gang',\n",
       "  'rival',\n",
       "  'billyboy',\n",
       "  'two',\n",
       "  'policemen',\n",
       "  'take',\n",
       "  'alex',\n",
       "  'outside',\n",
       "  'town',\n",
       "  'beat',\n",
       "  'dazed',\n",
       "  'bloodied',\n",
       "  'alex',\n",
       "  'collapses',\n",
       "  'door',\n",
       "  'isolated',\n",
       "  'cottage',\n",
       "  'realizing',\n",
       "  'late',\n",
       "  'house',\n",
       "  'droogs',\n",
       "  'invaded',\n",
       "  'first',\n",
       "  'half',\n",
       "  'story',\n",
       "  'gang',\n",
       "  'wore',\n",
       "  'masks',\n",
       "  'assault',\n",
       "  'writer',\n",
       "  'recognize',\n",
       "  'alex',\n",
       "  'writer',\n",
       "  'whose',\n",
       "  'name',\n",
       "  'revealed',\n",
       "  'alexander',\n",
       "  'shelters',\n",
       "  'alex',\n",
       "  'questions',\n",
       "  'conditioning',\n",
       "  'sequence',\n",
       "  'revealed',\n",
       "  'alexander',\n",
       "  'died',\n",
       "  'injuries',\n",
       "  'inflicted',\n",
       "  'husband',\n",
       "  'decided',\n",
       "  'continue',\n",
       "  'living',\n",
       "  'fragrant',\n",
       "  'memory',\n",
       "  'persists',\n",
       "  'despite',\n",
       "  'horrid',\n",
       "  'memories',\n",
       "  'alexander',\n",
       "  'critic',\n",
       "  'government',\n",
       "  'hopes',\n",
       "  'use',\n",
       "  'alex',\n",
       "  'symbol',\n",
       "  'state',\n",
       "  'brutality',\n",
       "  'thereby',\n",
       "  'prevent',\n",
       "  'incumbent',\n",
       "  'government',\n",
       "  'eventually',\n",
       "  'begins',\n",
       "  'realize',\n",
       "  'alex',\n",
       "  'role',\n",
       "  'happenings',\n",
       "  'night',\n",
       "  'two',\n",
       "  'years',\n",
       "  'ago',\n",
       "  'one',\n",
       "  'alexander',\n",
       "  'radical',\n",
       "  'associates',\n",
       "  'manages',\n",
       "  'extract',\n",
       "  'confession',\n",
       "  'alex',\n",
       "  'removing',\n",
       "  'alexander',\n",
       "  'home',\n",
       "  'locks',\n",
       "  'flatblock',\n",
       "  'near',\n",
       "  'former',\n",
       "  'home',\n",
       "  'alex',\n",
       "  'subjected',\n",
       "  'relentless',\n",
       "  'barrage',\n",
       "  'classical',\n",
       "  'music',\n",
       "  'prompting',\n",
       "  'attempt',\n",
       "  'suicide',\n",
       "  'leaping',\n",
       "  'high',\n",
       "  'window',\n",
       "  'alex',\n",
       "  'wakes',\n",
       "  'hospital',\n",
       "  'courted',\n",
       "  'government',\n",
       "  'officials',\n",
       "  'anxious',\n",
       "  'counter',\n",
       "  'bad',\n",
       "  'publicity',\n",
       "  'created',\n",
       "  'suicide',\n",
       "  'attempt',\n",
       "  'alexander',\n",
       "  'safely',\n",
       "  'packed',\n",
       "  'mental',\n",
       "  'institution',\n",
       "  'alex',\n",
       "  'offered',\n",
       "  'job',\n",
       "  'agrees',\n",
       "  'side',\n",
       "  'government',\n",
       "  'photographers',\n",
       "  'snap',\n",
       "  'pictures',\n",
       "  'alex',\n",
       "  'daydreams',\n",
       "  'orgiastic',\n",
       "  'violence',\n",
       "  'realizes',\n",
       "  'ludovico',\n",
       "  'conditioning',\n",
       "  'reversed',\n",
       "  'cured',\n",
       "  'right',\n",
       "  'final',\n",
       "  'chapter',\n",
       "  'alex',\n",
       "  'new',\n",
       "  'trio',\n",
       "  'droogs',\n",
       "  'finds',\n",
       "  'beginning',\n",
       "  'outgrow',\n",
       "  'taste',\n",
       "  'violence',\n",
       "  'chance',\n",
       "  'encounter',\n",
       "  'pete',\n",
       "  'married',\n",
       "  'settled',\n",
       "  'inspires',\n",
       "  'alex',\n",
       "  'seek',\n",
       "  'wife',\n",
       "  'family',\n",
       "  'contemplates',\n",
       "  'likelihood',\n",
       "  'future',\n",
       "  'son',\n",
       "  'delinquent',\n",
       "  'prospect',\n",
       "  'alex',\n",
       "  'views',\n",
       "  'fatalistically'],\n",
       " ['text',\n",
       "  'plague',\n",
       "  'divided',\n",
       "  'five',\n",
       "  'parts',\n",
       "  'town',\n",
       "  'oran',\n",
       "  'thousands',\n",
       "  'rats',\n",
       "  'initially',\n",
       "  'unnoticed',\n",
       "  'populace',\n",
       "  'begin',\n",
       "  'die',\n",
       "  'streets',\n",
       "  'hysteria',\n",
       "  'develops',\n",
       "  'soon',\n",
       "  'afterward',\n",
       "  'causing',\n",
       "  'local',\n",
       "  'newspapers',\n",
       "  'report',\n",
       "  'incident',\n",
       "  'authorities',\n",
       "  'responding',\n",
       "  'public',\n",
       "  'pressure',\n",
       "  'order',\n",
       "  'collection',\n",
       "  'cremation',\n",
       "  'rats',\n",
       "  'unaware',\n",
       "  'collection',\n",
       "  'catalyst',\n",
       "  'spread',\n",
       "  'bubonic',\n",
       "  'plague',\n",
       "  'main',\n",
       "  'character',\n",
       "  'bernard',\n",
       "  'rieux',\n",
       "  'lives',\n",
       "  'comfortably',\n",
       "  'apartment',\n",
       "  'building',\n",
       "  'strangely',\n",
       "  'building',\n",
       "  'concierge',\n",
       "  'michel',\n",
       "  'confidante',\n",
       "  'dies',\n",
       "  'fever',\n",
       "  'rieux',\n",
       "  'consults',\n",
       "  'colleague',\n",
       "  'castel',\n",
       "  'illness',\n",
       "  'come',\n",
       "  'conclusion',\n",
       "  'plague',\n",
       "  'sweeping',\n",
       "  'town',\n",
       "  'approach',\n",
       "  'fellow',\n",
       "  'doctors',\n",
       "  'town',\n",
       "  'authorities',\n",
       "  'theory',\n",
       "  'eventually',\n",
       "  'dismissed',\n",
       "  'basis',\n",
       "  'one',\n",
       "  'death',\n",
       "  'however',\n",
       "  'deaths',\n",
       "  'quickly',\n",
       "  'ensue',\n",
       "  'becomes',\n",
       "  'apparent',\n",
       "  'epidemic',\n",
       "  'authorities',\n",
       "  'including',\n",
       "  'prefect',\n",
       "  'othon',\n",
       "  'slow',\n",
       "  'accept',\n",
       "  'situation',\n",
       "  'serious',\n",
       "  'quibble',\n",
       "  'appropriate',\n",
       "  'action',\n",
       "  'take',\n",
       "  'official',\n",
       "  'notices',\n",
       "  'enacting',\n",
       "  'control',\n",
       "  'measures',\n",
       "  'posted',\n",
       "  'language',\n",
       "  'used',\n",
       "  'optimistic',\n",
       "  'downplays',\n",
       "  'seriousness',\n",
       "  'situation',\n",
       "  'special',\n",
       "  'ward',\n",
       "  'opened',\n",
       "  'hospital',\n",
       "  'beds',\n",
       "  'filled',\n",
       "  'within',\n",
       "  'three',\n",
       "  'days',\n",
       "  'death',\n",
       "  'toll',\n",
       "  'begins',\n",
       "  'rise',\n",
       "  'desperate',\n",
       "  'measures',\n",
       "  'taken',\n",
       "  'homes',\n",
       "  'quarantined',\n",
       "  'corpses',\n",
       "  'burials',\n",
       "  'strictly',\n",
       "  'supervised',\n",
       "  'supply',\n",
       "  'plague',\n",
       "  'serum',\n",
       "  'finally',\n",
       "  'arrives',\n",
       "  'enough',\n",
       "  'treat',\n",
       "  'existing',\n",
       "  'cases',\n",
       "  'country',\n",
       "  'emergency',\n",
       "  'reserves',\n",
       "  'depleted',\n",
       "  'daily',\n",
       "  'number',\n",
       "  'deaths',\n",
       "  'jumps',\n",
       "  'town',\n",
       "  'sealed',\n",
       "  'outbreak',\n",
       "  'plague',\n",
       "  'officially',\n",
       "  'declared',\n",
       "  'town',\n",
       "  'sealed',\n",
       "  'town',\n",
       "  'gates',\n",
       "  'shut',\n",
       "  'rail',\n",
       "  'travel',\n",
       "  'prohibited',\n",
       "  'mail',\n",
       "  'service',\n",
       "  'suspended',\n",
       "  'use',\n",
       "  'telephone',\n",
       "  'lines',\n",
       "  'restricted',\n",
       "  'urgent',\n",
       "  'calls',\n",
       "  'leaving',\n",
       "  'short',\n",
       "  'telegrams',\n",
       "  'means',\n",
       "  'communicating',\n",
       "  'friends',\n",
       "  'family',\n",
       "  'outside',\n",
       "  'town',\n",
       "  'separation',\n",
       "  'affects',\n",
       "  'daily',\n",
       "  'activity',\n",
       "  'depresses',\n",
       "  'spirit',\n",
       "  'townspeople',\n",
       "  'begin',\n",
       "  'feel',\n",
       "  'isolated',\n",
       "  'introverted',\n",
       "  'plague',\n",
       "  'begins',\n",
       "  'affect',\n",
       "  'various',\n",
       "  'characters',\n",
       "  'one',\n",
       "  'character',\n",
       "  'raymond',\n",
       "  'rambert',\n",
       "  'devises',\n",
       "  'plan',\n",
       "  'escape',\n",
       "  'city',\n",
       "  'join',\n",
       "  'lover',\n",
       "  'paris',\n",
       "  'city',\n",
       "  'officials',\n",
       "  'refuse',\n",
       "  'request',\n",
       "  'leave',\n",
       "  'befriends',\n",
       "  'criminals',\n",
       "  'may',\n",
       "  'smuggle',\n",
       "  'city',\n",
       "  'another',\n",
       "  'character',\n",
       "  'father',\n",
       "  'paneloux',\n",
       "  'uses',\n",
       "  'plague',\n",
       "  'opportunity',\n",
       "  'advance',\n",
       "  'stature',\n",
       "  'town',\n",
       "  'suggesting',\n",
       "  'plague',\n",
       "  'act',\n",
       "  'god',\n",
       "  'punishing',\n",
       "  'citizens',\n",
       "  'sinful',\n",
       "  'nature',\n",
       "  'diatribe',\n",
       "  'falls',\n",
       "  'ears',\n",
       "  'many',\n",
       "  'citizens',\n",
       "  'town',\n",
       "  'turned',\n",
       "  'religion',\n",
       "  'droves',\n",
       "  'would',\n",
       "  'done',\n",
       "  'normal',\n",
       "  'circumstances',\n",
       "  'cottard',\n",
       "  'criminal',\n",
       "  'remorseful',\n",
       "  'enough',\n",
       "  'attempt',\n",
       "  'suicide',\n",
       "  'yet',\n",
       "  'fearful',\n",
       "  'arrested',\n",
       "  'becomes',\n",
       "  'wealthy',\n",
       "  'major',\n",
       "  'smuggler',\n",
       "  'meanwhile',\n",
       "  'rieux',\n",
       "  'vacationer',\n",
       "  'jean',\n",
       "  'tarrou',\n",
       "  'civil',\n",
       "  'servant',\n",
       "  'joseph',\n",
       "  'grand',\n",
       "  'exhaustively',\n",
       "  'treat',\n",
       "  'patients',\n",
       "  'homes',\n",
       "  'hospital',\n",
       "  'rambert',\n",
       "  'informs',\n",
       "  'tarrou',\n",
       "  'escape',\n",
       "  'plan',\n",
       "  'tarrou',\n",
       "  'tells',\n",
       "  'others',\n",
       "  'city',\n",
       "  'including',\n",
       "  'rieux',\n",
       "  'also',\n",
       "  'loved',\n",
       "  'ones',\n",
       "  'outside',\n",
       "  'city',\n",
       "  'allowed',\n",
       "  'see',\n",
       "  'rambert',\n",
       "  'becomes',\n",
       "  'sympathetic',\n",
       "  'changes',\n",
       "  'mind',\n",
       "  'decides',\n",
       "  'join',\n",
       "  'tarrou',\n",
       "  'rieux',\n",
       "  'help',\n",
       "  'fight',\n",
       "  'epidemic',\n",
       "  'situation',\n",
       "  'continues',\n",
       "  'worsen',\n",
       "  'people',\n",
       "  'try',\n",
       "  'escape',\n",
       "  'town',\n",
       "  'shot',\n",
       "  'armed',\n",
       "  'sentries',\n",
       "  'violence',\n",
       "  'looting',\n",
       "  'break',\n",
       "  'small',\n",
       "  'scale',\n",
       "  'authorities',\n",
       "  'respond',\n",
       "  'declaring',\n",
       "  'martial',\n",
       "  'law',\n",
       "  'imposing',\n",
       "  'curfew',\n",
       "  'funerals',\n",
       "  'conducted',\n",
       "  'speed',\n",
       "  'ceremony',\n",
       "  'little',\n",
       "  'concern',\n",
       "  'feelings',\n",
       "  'families',\n",
       "  'deceased',\n",
       "  'inhabitants',\n",
       "  'passively',\n",
       "  'endure',\n",
       "  'increasing',\n",
       "  'feelings',\n",
       "  'exile',\n",
       "  'separation',\n",
       "  'despondent',\n",
       "  'waste',\n",
       "  'away',\n",
       "  'emotionally',\n",
       "  'well',\n",
       "  'physically',\n",
       "  'september',\n",
       "  'october',\n",
       "  'town',\n",
       "  'remains',\n",
       "  'mercy',\n",
       "  'plague',\n",
       "  'rieux',\n",
       "  'hears',\n",
       "  'sanatorium',\n",
       "  'wife',\n",
       "  'condition',\n",
       "  'worsening',\n",
       "  'also',\n",
       "  'hardens',\n",
       "  'heart',\n",
       "  'regarding',\n",
       "  'plague',\n",
       "  'victims',\n",
       "  'continue',\n",
       "  'work',\n",
       "  'cottard',\n",
       "  'hand',\n",
       "  'seems',\n",
       "  'flourish',\n",
       "  'plague',\n",
       "  'gives',\n",
       "  'sense',\n",
       "  'connected',\n",
       "  'others',\n",
       "  'since',\n",
       "  'everybody',\n",
       "  'faces',\n",
       "  'danger',\n",
       "  'cottard',\n",
       "  'tarrou',\n",
       "  'attend',\n",
       "  'performance',\n",
       "  'gluck',\n",
       "  'opera',\n",
       "  'orpheus',\n",
       "  'eurydice',\n",
       "  'actor',\n",
       "  'portraying',\n",
       "  'orpheus',\n",
       "  'collapses',\n",
       "  'plague',\n",
       "  'symptoms',\n",
       "  'performance',\n",
       "  'rambert',\n",
       "  'finally',\n",
       "  'chance',\n",
       "  'escape',\n",
       "  'decides',\n",
       "  'stay',\n",
       "  'saying',\n",
       "  'would',\n",
       "  'feel',\n",
       "  'ashamed',\n",
       "  'left',\n",
       "  'towards',\n",
       "  'end',\n",
       "  'october',\n",
       "  'castel',\n",
       "  'new',\n",
       "  'serum',\n",
       "  'tried',\n",
       "  'first',\n",
       "  'time',\n",
       "  'save',\n",
       "  'life',\n",
       "  'othon',\n",
       "  'young',\n",
       "  'son',\n",
       "  'suffers',\n",
       "  'greatly',\n",
       "  'paneloux',\n",
       "  'rieux',\n",
       "  'tarrou',\n",
       "  'look',\n",
       "  'horror',\n",
       "  'paneloux',\n",
       "  'joined',\n",
       "  'group',\n",
       "  'volunteers',\n",
       "  'fighting',\n",
       "  'plague',\n",
       "  'gives',\n",
       "  'second',\n",
       "  'sermon',\n",
       "  'addresses',\n",
       "  'problem',\n",
       "  'innocent',\n",
       "  'child',\n",
       "  'suffering',\n",
       "  'says',\n",
       "  'test',\n",
       "  'christian',\n",
       "  'faith',\n",
       "  'since',\n",
       "  'requires',\n",
       "  'either',\n",
       "  'deny',\n",
       "  'everything',\n",
       "  'believe',\n",
       "  'everything',\n",
       "  'urges',\n",
       "  'congregation',\n",
       "  'give',\n",
       "  'struggle',\n",
       "  'everything',\n",
       "  'possible',\n",
       "  'fight',\n",
       "  'plague',\n",
       "  'days',\n",
       "  'sermon',\n",
       "  'paneloux',\n",
       "  'taken',\n",
       "  'symptoms',\n",
       "  'conform',\n",
       "  'plague',\n",
       "  'disease',\n",
       "  'still',\n",
       "  'proves',\n",
       "  'fatal',\n",
       "  'tarrou',\n",
       "  'rambert',\n",
       "  'visit',\n",
       "  'one',\n",
       "  'isolation',\n",
       "  'camps',\n",
       "  'meet',\n",
       "  'othon',\n",
       "  'othon',\n",
       "  'period',\n",
       "  'quarantine',\n",
       "  'ends',\n",
       "  'elects',\n",
       "  'stay',\n",
       "  'camp',\n",
       "  'volunteer',\n",
       "  'make',\n",
       "  'feel',\n",
       "  'less',\n",
       "  'separated',\n",
       "  'dead',\n",
       "  'son',\n",
       "  'tarrou',\n",
       "  'tells',\n",
       "  'rieux',\n",
       "  'story',\n",
       "  'life',\n",
       "  'two',\n",
       "  'men',\n",
       "  'go',\n",
       "  'swimming',\n",
       "  'together',\n",
       "  'sea',\n",
       "  'grand',\n",
       "  'catches',\n",
       "  'plague',\n",
       "  'instructs',\n",
       "  'rieux',\n",
       "  'burn',\n",
       "  'papers',\n",
       "  'grand',\n",
       "  'makes',\n",
       "  'unexpected',\n",
       "  'recovery',\n",
       "  'deaths',\n",
       "  'plague',\n",
       "  'start',\n",
       "  'decline',\n",
       "  'late',\n",
       "  'january',\n",
       "  'plague',\n",
       "  'full',\n",
       "  'retreat',\n",
       "  'townspeople',\n",
       "  'begin',\n",
       "  'celebrate',\n",
       "  'imminent',\n",
       "  'opening',\n",
       "  'town',\n",
       "  'gates',\n",
       "  'othon',\n",
       "  'however',\n",
       "  'escape',\n",
       "  'death',\n",
       "  'disease',\n",
       "  'cottard',\n",
       "  'distressed',\n",
       "  'ending',\n",
       "  'epidemic',\n",
       "  'profited',\n",
       "  'shady',\n",
       "  'dealings',\n",
       "  'two',\n",
       "  'government',\n",
       "  'employees',\n",
       "  'approach',\n",
       "  'flees',\n",
       "  'despite',\n",
       "  'epidemic',\n",
       "  'ending',\n",
       "  'tarrou',\n",
       "  'contracts',\n",
       "  'plague',\n",
       "  'dies',\n",
       "  'heroic',\n",
       "  'struggle',\n",
       "  'rieux',\n",
       "  'wife',\n",
       "  'also',\n",
       "  'dies',\n",
       "  'february',\n",
       "  'town',\n",
       "  'gates',\n",
       "  'open',\n",
       "  'people',\n",
       "  'reunited',\n",
       "  'loved',\n",
       "  'ones',\n",
       "  'cities',\n",
       "  'rambert',\n",
       "  'reunited',\n",
       "  'wife',\n",
       "  'rieux',\n",
       "  'reveals',\n",
       "  'narrator',\n",
       "  'chronicle',\n",
       "  'tried',\n",
       "  'present',\n",
       "  'objective',\n",
       "  'view',\n",
       "  'events',\n",
       "  'cottard',\n",
       "  'goes',\n",
       "  'mad',\n",
       "  'shoots',\n",
       "  'people',\n",
       "  'home',\n",
       "  'arrested',\n",
       "  'grand',\n",
       "  'begins',\n",
       "  'working',\n",
       "  'sentence',\n",
       "  'rieux',\n",
       "  'reflects',\n",
       "  'epidemic',\n",
       "  'reaches',\n",
       "  'conclusion',\n",
       "  'admire',\n",
       "  'despise',\n",
       "  'humans']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = words_process(new_file.iloc[0:3, :]) ####NEED TO CHANGE TO ALL!!!!!!!\n",
    "all_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## outliners ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Pre-Trained Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Word2Vec loading capabilities\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Creating the model\n",
    "embed_lookup = KeyedVectors.load_word2vec_format('./CNN_Text_Classification/word2vec_model/word2vec-slim/GoogleNews-vectors-negative300.bin', \n",
    "                                                 binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_all_sum(embed_lookup):\n",
    "    tokenized_sum = []\n",
    "    for summ in all_words:\n",
    "        ints = []\n",
    "        for w in summ:\n",
    "            try:\n",
    "                idx = embed_lookup.vocab[w].index\n",
    "            except: \n",
    "                idx = 0\n",
    "            ints.append(idx)\n",
    "        tokenized_sum.append(ints)\n",
    "    return tokenized_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sum = tokenize_all_sum(embed_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[154, 338, 154, 86316, 63917, 2563, 926, 2418, 2563, 349, 8691, 5103, 32366, 7328, 2418, 8709, 2216, 146659, 338, 6119, 54, 533, 13250, 37391, 517953, 4315, 3929, 749, 2768, 5868, 2418, 14076, 817, 18500, 11132, 94620, 131280, 2563, 35097, 2801, 2563, 4922, 375, 60262, 396, 2418, 3325, 37391, 2687, 4016, 2418, 1772, 2009, 560, 18855, 2563, 623, 9841, 13250, 18603, 1784, 1274, 211, 3125, 605, 560, 1281, 22341, 764, 492, 517953, 920, 38308, 2563, 2766, 5325, 9223, 517953, 37391, 2894, 1274, 37391, 5513, 383, 857, 45282, 517953, 2766, 5148, 37391, 309, 15156, 614, 517953, 75114, 726, 6481, 2351, 2563, 5226, 1778, 956, 13250, 209, 2563, 527, 533, 13283, 945, 798371, 34858, 517953, 1059, 912, 45282, 931, 2418, 141, 3437, 3102, 2200, 870, 45282, 3148, 1896, 2418, 359, 45282, 66096, 517953, 798371, 5823, 2418, 37391, 3016, 1021, 34168, 0, 2470, 3064, 4406, 5160, 37391, 2540, 29160, 517953, 2219, 50487, 2563, 2766, 1423, 2418, 11092, 174391, 154, 2318, 13250, 2258, 325, 9174, 509, 36632, 12891, 33177, 576, 0, 37391, 66524, 517953, 798371, 29457, 274, 489, 517953, 638, 155, 13250, 28470, 375, 60262, 1090552, 1096, 146659, 2588, 20467, 66524, 517953, 1530, 9224, 4734, 251, 2418, 872, 4233, 254, 94620, 131280, 798371, 8622, 2418, 1268, 4829, 87799, 1052, 261, 2249, 94620, 1868397, 45, 0, 2470, 1020, 2563, 527, 16778, 11860, 3252, 5757, 45282, 459, 2418, 202, 1508, 267, 370, 131, 143, 13959, 32408, 2691, 865, 1481, 13959, 1206, 345, 3437, 3437, 20628, 345, 45282, 517953, 6560, 5040, 142, 13959, 16356, 11075, 6553, 254, 643, 482, 971843, 15879, 30560, 75, 1025, 112, 13283, 9616, 5040, 8314, 1018880, 2687, 9117, 2381, 2418, 2687, 20585, 798371, 613, 5040, 2793, 825, 2009, 721, 1140, 59619, 21980, 7013, 13959, 570, 1157, 201, 788, 643, 77, 901, 13250, 1234, 1505, 16856, 1635, 36992, 3015, 3874, 375, 60262, 1823, 649, 7880, 2418, 3325, 2418, 3325, 488, 517953, 2237, 2656, 447, 13250, 5103, 272, 12870, 517953, 328, 5554, 2418, 198, 517953, 5513, 4074, 5103, 0, 2251, 9539, 129908, 2240, 8816, 734, 6372, 726, 521, 2563, 63917, 2563, 2418, 127255, 3399, 2432, 1608, 13250, 3347, 2192, 8136, 624, 3371, 3853, 517953, 94620, 0, 2418, 0, 1608, 13250, 329, 87, 1608, 5103, 45, 888, 1567, 13250, 37391, 517953, 798371, 8448, 154, 338, 2122, 2769, 5868, 5462, 521, 1090552, 774, 517953, 798371, 19381, 51939, 5103, 3273, 2330, 6911, 7676, 832, 798371, 4578, 9240, 375, 60262, 1201, 817491, 61536, 167332, 121, 23141, 576, 555, 2437, 509, 68, 6518, 1979, 1412, 60262, 2341, 1047, 1472, 54, 4237, 4980, 2341, 1047, 1472, 134, 4237, 8933, 1269, 2801, 4034, 3015, 3874, 2801, 4034, 3629, 3126, 2801, 4034, 3554, 2330, 2801, 4034, 2176, 2801, 2418, 3325, 334, 517953, 13250, 11693, 8243, 60262, 645, 6157, 2801, 4034, 3554, 2330, 4668, 84951, 2801, 4034, 3629, 3126, 10383, 264, 1327, 60262, 3120, 726, 245227, 2801, 4034, 3629, 3126, 10383, 2801, 4034, 3554, 2330, 4668, 2801, 4034, 2176, 2801, 294, 953, 1702, 2588, 161863, 2418, 3325, 2418, 3325, 488, 134, 4237, 127, 54, 4237, 254, 13250, 411, 1275, 14156, 8127, 1412, 2578, 375, 60262, 2402, 350, 555, 405, 2801, 2563, 26608, 2418, 526, 5103, 1559, 2418, 486, 5103, 6040, 8053, 12207, 60262, 0, 7541, 1197, 450, 44923, 760, 72489, 9792]\n"
     ]
    }
   ],
   "source": [
    "# testing code and printing a tokenized review\n",
    "print(tokenized_sum[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "599"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_Length = 0  \n",
    "for x in tokenized_sum:\n",
    "    if len(x) > max_Length:\n",
    "        max_Length = len(x)\n",
    "max_Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_features(tokenized_sum, seq_length):\n",
    "    \n",
    "    # getting the correct rows x cols shape\n",
    "    features = np.zeros((len(tokenized_sum), seq_length), dtype=int)\n",
    " \n",
    "    # for each review, I grab that review and \n",
    "    for i, row in enumerate(tokenized_sum):\n",
    "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2986   17170    4730     161    1286     644       0    1009   14141\n",
      "    2613   20840   25965     994    2736    1852   26879    7687     774\n",
      "    8400    2733     290    3828     243    1291     892    5549     208\n",
      "     869     555    2179   34977   14141    8881    2179   11278    1789\n",
      "  900125   17170     828    1980 1040078       0     870   11029    2743\n",
      "     473   24762     473   34562 1671245   58915    6119   10756       0\n",
      "   41957    7383       0    4696     216    4523   17170    6378     644\n",
      "    1247    1969    1912     644     892    5003    1702    3217    1166\n",
      "      45     570     713    2164     966   40575    2540    4004   11185\n",
      "     892     143   66377       0    1803    2013     768     981   54833\n",
      "    2375     598     142     581    9616   26419     509    1448    1175\n",
      "    1828     233    4358   59267   14358     768     605    9620    1046\n",
      "     825    7676    2217     405      80     255     570    4137    2219\n",
      "    1027    4983    1448     433     942   28196   20949   43034    9307\n",
      "   11849    1465   17170   39898    1302    7032     410    3000    1259\n",
      "     883     198    1313    3137   14087    1349     246    2164   10147\n",
      "     644    6029    6409   17170    3370    2241     644    6029     644\n",
      "    8291    2233    3904    1117    7236    3193     277    2297     204\n",
      "    2660    1495    5515    6368     926    1265     585  113649     728\n",
      "   12116     805     244     586     644    7965    6024    1349    1394\n",
      "  103228    3376   38669     994     574    6235   73213   17170    2219\n",
      "    2220    1068    3304      45    1980  784785       0   97713     326\n",
      "    3743     219    1409   10472  198365     219     247    6496    1592\n",
      "     785   65648    6074     137   23724     219     197    1980     913\n",
      "       0    2113   17170     703    1998   14435     644    4752   17170\n",
      "    1426   14033   15035    1680   45205    1963   55718    3731    8817\n",
      "     131    1680     644     760    4115   24861      47     449    1845\n",
      "    2669       0    1739   39828     410    1476    3921     506   14458\n",
      "     849    2540    6162     338   46819    4076       0  171657  102952\n",
      "       0    2323   17005  451395    5054   98791    3000     919     942\n",
      "     825       0   20801       0    3743     326       0    2710     488\n",
      "     219     143       0      53    3069    1813     586     219     736\n",
      "     158       0    2540   13132     726    1252    7073    1409       0\n",
      "       0     173     821   11185     768    1206   15003      68     627\n",
      "    3743     644     441    3115  133968    1167   15963     843     428\n",
      "    2316     892    2523    9063   22112     404    9174   12733   19561\n",
      "    1904    1250    2194     286    1525    5258     916    9895   14879\n",
      "   48747   11947    1553    5258   10178    7965   43992    2615     309\n",
      "   10769     112    5642  166235  179001     644     986   12627   17170\n",
      "       0   14456  186781     783    1333   12345      53   97662    1089\n",
      "    1785   17170    1370     395     141       0     660    1006   14996\n",
      "   17170    1336    1170    2940     488     140    2207    1608    3149\n",
      "       0       0    1753     475       0   10044       0       0    2668\n",
      "   18967       0   20628   17170    4395     475       0    1302     608\n",
      "    3743    7073     820     478      47     574   14368     196    1716\n",
      "     178  179001       0      65   39898     940      56      59    1114\n",
      "     258       0     533     831    9549    5634       0       0       0\n",
      "     329    7213       0    1335     229    2645    1385   17170    1336\n",
      "     110   18827    5263     600    5017     795    2597     115     889\n",
      "   88925    2605     140    2336     799    5092     838     480     838\n",
      "    8876   10142     331    2894     838     522     821   17170     255\n",
      "   18827       0     433    4395   16760   17170    1935     151    8422\n",
      "    5365       0       0     633      45    9594    5147     584       0\n",
      "       0     461   17626    2478   37226     820    2069    3496     109\n",
      "     574     373    6721    1161     831       0    2710       0     550\n",
      "     258      54     437     152    5887     526    2854    5054    5484\n",
      "   17170   37904       0    5566    3637    5054     638    5243    1470\n",
      "    2164   17170     284    1686     401  175888   17170     335    8217\n",
      "   38669     994    3040    8651     798     644    8291       0     713\n",
      "    3743     570    1935       0   12703    2017   11185   30952   24117\n",
      "   12025      54     121     725    1247   51315     865   11185    2017\n",
      "       0    1997   17170    6119   15299    2894       0     783      53\n",
      "    6119  241361     644    8291     341      68   13081    3069    1813\n",
      "    1623       0   13081     783       0    6346   25265   31519     940\n",
      "    1018    4591     995     696       0    1047    7966   11454      68\n",
      "     124     849    5054    2219     345    2303       0    4292   11185\n",
      "    6523    4523   13421   40364    5103]\n"
     ]
    }
   ],
   "source": [
    "features = pad_features(tokenized_sum, max_Length)\n",
    "\n",
    "assert len(features)==len(tokenized_sum), \"Features should have as many rows as reviews.\"\n",
    "assert len(features[0])==max_Length, \"Each feature row should contain seq_length values.\"\n",
    "\n",
    "print(features[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, Validation, and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(2, 599) \n",
      "Validation set: \t(0, 599) \n",
      "Test set: \t\t(1, 599)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "\n",
    "split_idx = int(len(features)*split_frac)\n",
    "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
    "train_y, remaining_y = one_hot[:split_idx], one_hot[split_idx:]\n",
    "\n",
    "test_idx = int(len(remaining_x)*0.5)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
    "\n",
    "## print out the shapes of your resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Above only 2,0,1 because I only used  3 datasample to do all of these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
